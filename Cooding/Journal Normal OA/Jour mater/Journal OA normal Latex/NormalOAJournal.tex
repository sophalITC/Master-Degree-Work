\documentclass[review]{elsarticle}
\usepackage{amsmath}
\usepackage{lineno,hyperref}
\usepackage{siunitx}
\usepackage{csquotes}
\usepackage[table]{xcolor}
\usepackage{slashbox,booktabs}
\usepackage{setspace}
\modulolinenumbers[5]

%\journal{Journal of \LaTeX\ Templates}

%%%%%%%%%%%%%%%%%%%%%%%
%% Elsevier bibliography styles
%%%%%%%%%%%%%%%%%%%%%%%
%% To change the style, put a % in front of the second line of the current style and
%% remove the % from the second line of the style you would like to use.
%%%%%%%%%%%%%%%%%%%%%%%

%% Numbered
%\bibliographystyle{model1-num-names}

%% Numbered without titles
%\bibliographystyle{model1a-num-names}

%% Harvard
%\bibliographystyle{model2-names.bst}\biboptions{authoryear}

%% Vancouver numbered
%\usepackage{numcompress}\bibliographystyle{model3-num-names}

%% Vancouver name/year
%\usepackage{numcompress}\bibliographystyle{model4-names}\biboptions{authoryear}

%% APA style
%\bibliographystyle{model5-names}\biboptions{authoryear}

%% AMA style
%\usepackage{numcompress}\bibliographystyle{model6-num-names}

%% `Elsevier LaTeX' style
\bibliographystyle{elsarticle-num}
%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
	
	\begin{frontmatter}
		
		\title{A Comparative Study of Texture Analysis Techniques for Osteoarthritis Classification Using Knee X-ray Imagery}
		%\tnotetext[mytitlenote]{Fully documented templates are available in the elsarticle package on \href{http://www.ctan.org/tex-archive/macros/latex/contrib/elsarticle}{CTAN}.}
		
		%% Group authors per affiliation:
		%\author{Elsevier\fnref{myfootnote}}
		%\address{Radarweg 29, Amsterdam}
		%\fntext[myfootnote]{Since 1880.}
		
		\author[mymainaddress]{Sophal Chan}
		\ead{sophal.c@phuket.psu.ac.th}
		\author[mymainaddress]{Kwankamon Dittakan}
		\ead{kwankamon.d@phuket.psu.ac.th}
		\author[mysecondaryaddress]{Matias Garcia-Constantino}
		\ead{m.garcia-constantino@ulster.ac.uk}
		%% or include affiliations in footnotes:
		
		
		%\author[mysecondaryaddress]{Global Customer Service\corref{mycorrespondingauthor}}
		\cortext[mycorrespondingauthor]{Corresponding author}
		%\ead{support@elsevier.com}
		
		\address[mymainaddress]{College of Computing, Prince of Songkla University, 80, Moo 1, Vichitsongkram Rd, Kathu, Kathu, Phuket, Thailand 83120}
		\address[mysecondaryaddress]{School of Computing, Ulster University, Shore Road, Newtownabbey, County Antrim, BT37 0QB, United Kingdom}
		
		\begin{abstract}
			Knee Osteoarthritis (OA) is one of the most prominent diseases in aging society and has affected over 10 million people in Thailand. When people suffer from OA it is very difficult to recover back, therefore early detection and prevention are very important. The typical way to detect OA is by using X-ray imaging. This research study is focused on early detection of OA by applying image processing and classification techniques to knee X-ray imagery. The fundamental concept is to find a region of interest, use feature extraction techniques and generate a classiﬁer that is able to distinguish between OA or non-OA images. Firstly, texture analysis is adopted in the research for analyzing the properties of the bone surface of four regions of interest (ROI): (i) Medial Femur (MF), (ii) Lateral Femur (LF), (iii) Medial Tibia (MT), and (iv) Lateral Tibia (LT). Secondly, feature selection is applied to reduce the size of the feature space in terms of number of values and dimensions. Finally, the classifier generator is used to classify imagery between OA and non-OA. The challenge is how to know which regions of interest are suitable to use for the classification process. The data from 131 male and female participants was used for the evaluation. The results obtained show that LF is the most appropriate region of interest to consider. Amongst the results obtained for LF, there was an AUC (Area Under the ROC Curve) result of 0.912. The evaluation and results are described in detail.
		\end{abstract}
		
		\begin{keyword}
			Texture Analysis, Osteoarthritis, Knee OA, Image Classification.
		\end{keyword}
		
	\end{frontmatter}
	
	\linenumbers
\section{Introduction}

Osteoarthritis (OA) is a degenerative joint disease which happens in human joints. OA is the most prevalent disease of the joints in the aging society and the most common disease of arthritis which affects millions of people in the United States \cite{Factors2000}. In Thailand the people affected with OA has almost reached 10 million, which is 13\% of Thailand's population, as reported by the National Statistical Office (NSO) in 2014. The NSO also reports that Thailand is going to be an aging society country in ten years. In the aging society, knee OA affects approximately 10\% of men and 13\% of women \cite{BoneandJointInitiativeUSA2014}. Symptoms of knee OA can be detected by the presence of pain, swelling, stiffness in the knee, reduced ability of movement and cracking sound when the knee is moved. Furthermore, OA can be detected early by using medical images to prevent the progression to a more severe stage. Medical imaging that are widely used for OA early detection include: (i) X-ray image, (ii) Computed Tomography (CT) and (iii) Magnetic Resonance Imaging (MRI). The figure below is shown the image of knee X-ray image for (a)Normal and (b) OA case: \\
\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\linewidth]{pic/picOA}
	\caption{Normal and Osteoarthritis(OA) Knee X-ray Imagery}
	\label{fig:picoa}
\end{figure}



The aim of this research is to apply image processing techniques on medical X-ray images to detect OA. Image processing is a technology in which algorithms can be used to enhance the image or extract some useful features from the image to study for any specific purpose. Image processing is, for example, typically used in fields like: biology, medicine, astronomy and biometrics. In other words, image processing is a specific technology used for (i) classification, (ii) feature extraction, (iii) multi-scale signal analysis, (iv) pattern recognition and (v) projection. The implementation of image processing for classification in medical X-ray images is proposed in this work. 

The motivation of the research presented is on the classification of the OA and non-OA X-ray images from four sub-images of the knee in terms of the following regions of interest (ROI): (i) Lateral Femur (FM), (ii) Lateral Tibia (LT), (iii) Medial Femur (MF), and (iv) Medial Tibia (MT). The analysis of an image can be done in three main ways including: (i) color-based analysis, (ii) shape analysis, and (iii) texture analysis. Texture analysis is the appropriate way to analyze X-ray images. A texel is the basic unit of a graphic in terms of texture. A texture is a set of texels occurring in some regular or repeated pattern. In other words, texture can produce the information about the spatial arrangement of intensity in an image or selected region of an image. In addition, texture can be analyzed by texture descriptors, which is a technique that can use statistics, filter banks, auto-correlation, etc. The texture descriptors considered in this research work are: (i) histogram feature, (ii) Local Binary Pattern (LBP), (iii) Completed LBP (CLBP), (iv) Rotated LBP (RLBP), (v) LBP Rotation Invariant (LBP\textsubscript{ri}), (vi) LBP Histogram Fourier (LBP-HF), (vii) Local Ternary Pattern (LTP), (viii) Local Configuration Pattern (LCP), (ix) Haralick feature, and (x) Gabor filter feature. As a result, the proposed framework suggested that LBP is the most appropriate texture descriptor for this research study. 

% In addition, the texture feature analysis is used to classify the OA or non-OA in the research while there are 10 techniques of texture analysis are used include: i) The first level of Gray-Level Co-Occurrence Matrix (GLCM), ii) Local Binary Pattern (LBP), iii) Completed LBP (CLBP), iv) Rotated LBP (RLBP), v) LBP Histogram Fourier (LBP\_HF), vi) LBP Rotation Invariant (LBP\_ri), vii) Gabor, viii) Haralick, ix) Local Configuration Pattern (LCP) and x) Local Ternary Pattern (LTP). Next, the ten texture feature descriptor is applied with five different feature selection include: i) Correlation-based Feature Selection (CFS), ii) Chi-square, iii) Gain Ration, iv) Information Gain and v) Relief. Lastly, the learning algorithms are applied to get the final result of the work, learning algorithm is presented in the work include: i) Decision Tree(C 4.5), ii) Decision with binary true, iii) Average One-Dependence Estimators (AODE), iv) Bayesian Network, v) Naïve Bayesian Classifier, vi) Support Vector Machine (SVM), vii) Logistic, viii) Sequential Minimal Optimization, and ix) The backpropagation algorithm.

The proposed technique has three major advantages: (i) fast speed processing, (ii) can be applied in a future study with different imaging modalities, and (iii) can help non-specialist researchers or new profession MDs (Medical Doctors) to analyze OA/non-OA images. On the other hand, the proposed framework still has three main limitations: (i) it is a semi-automatic system which needs an action from a human to chose the ROI, (ii) the dataset is not large enough, and (iii) the result of the experiment is under control from researchers.\\

The remainder of the paper is organised as follows. Section 2 presents related work and Section 3 discusses the proposed framework. Information about each texture feature descriptor is presented in Section 4. Section 5 presents the description of the feature selection and classification algorithms used. Section 6 presents the details about the data collection and Section 7 discusses the evaluation. Finally, conclusions are presented in Section 8. 

\section{Related Work}

In recent years there has been substantial research work in OA detection and classification \cite{Wolski2010, Jin2013, Shamir2009, S.2016, Kotti2017}. The early detection of OA can be applied to medical imaging and used in conjunction with a professional clinician to classify the OA. On the other hand, the implementation of classification techniques to medical imaging for OA detection has been considered as an interesting topic in image processing research fields. Texture is one of the most important properties in images as it shows the arrangement of pixels in objects to analyze. Therefore, texture is one of the useful solutions in medical image processing for diagnosis and detection of OA in a clinical setting \cite{Castellano2004, Janvier2015}. In \cite{Wolski2010}, the research focused on the ROI of tibia texture for the analysis of OA. Texture analysis can be applied to different types of medical images including: X-ray \cite{Wolski2010}, MRI \cite{Chuah2011}, CT, and Infrared \cite{Jin2013}. In addition, the texture of an object can be analyzed using texture descriptors, which is a technique to represent and handle texture in a numeric form. Texture descriptors include: LBP \cite{Castellano2004, Dittakan2016, Kachouie2007}, CLBP \cite{Guo2010}, LBP\_ri \cite{Varney2015}, LBP-HF \cite{Prasad2016}, and LTP \cite{Tan2010, Wang2014}. \\

The study presented in \cite{S.2016} introduced a method to analyze knee OA X-ray images which combined different types of features: (i) shape, (ii) statistical, (iii) Haralick, (iv) texture analysis and (v) first-four moments features. The classification algorithm used in \cite{S.2016} was Random Forest with the data divided into 40\% for training and 60\% for testing. The features considered in \cite{Kawathekar2015} to analyze texture for radiographic OA of knee joint were: (i) entropy, (ii) mean, (iii) median, (iv) standard deviation, (v) variance, and (vi) Tamura texture features. \\

Furthermore, texture analysis has been widely used in the medical field for the detection of various diseases including: tumour heterogeneity \cite{Liu2017, Miles2013}, brain tumour \cite{Weltens2001}, head and neck cancer \cite{Yu2009}, breast cancer \cite{Zhou2007}, emphysema \cite{Xu2006,Vasconcelos}, vascular segmentation \cite{PoddaB.2005, Ahmed2013}, TRUS (transrectal ultrasound) prostate segmentation \cite{Yuan2013, Kachouie2007}, colon cancer \cite{Esgiar2002}, small vessel disease and blood brain barrier \cite{ValdesHernandez2017}, skin cancer \cite{Ntroduction2014}, and lung cancer \cite{Pham2017}.
%LBP is introduced in work [pa], the application of LBP in the work can detected knee OA x-ray image with the implementation of machine learning include: (i) Naïve Bayes, (ii) Decision Tree(C4.5) , (iii) Sequential Minimal Optimisation (SMO), (iv) Back Propagation Neural Networks and (v) Logistic Regression.
\section{Proposed Framework }


\begin{figure}[h!]
	\centering
	\includegraphics[width=0.99\linewidth]{pic/fig1}
	\caption{Texture Analysis on Knee OA Classification Techniques}
	\label{fig:fig1}
\end{figure}
The proposed framework presented in figure 2 shows the three main processes considered: (i) Region of interest (ROI) selection, (b) texture extraction, and (c) classification. First and foremost, in order to detect OA/non-OA imagery by using texture analysis it is required to have good quality sub-images of texture. ROI selection is used to select the specific area or sub-image which is considered to have the unique identity for detecting OA by using texture analysis. The ROIs in this process are selected from four different areas as shown in Figure 2(a): (i) two on the femur bone on the lateral and medial side, and (ii) two on the tibia on the lateral and medial side. The output of the ROI selection process are the four ROIs: (i) Medial Femur (MF) ROI, (ii) Lateral Femur (LF) ROI, (iii) Medial Tibia (MT) ROI, and (iv) Lateral Tibia (LT) ROI. The output of the ROI selection process is used as the input of the texture extraction process. \\

Texture extraction (refer to Figure 2(b)) was used to extract texture of each sub-image from Figure 2(a). Feature extraction is a process used to reduce the size of the feature space in terms of the number of values and dimensions. Feature descriptor is a technique widely used to extract features. The research study presented here considered ten different feature extraction techniques, with six of them belonging to the Local Binary Pattern (LBP) family. LBP is a well known texture descriptor technique which is used to analyze the centre pixel in relation to neighboring pixels. In addition to LBP, another six feature descriptors related to LBP applied in this research are: (i) LBP Histogram Fourier (LBP-HF), (ii) LBP Rotation Invariant (LBP\textsubscript{ri}), (iii) Completed LBP (CLBP), (iv) Local Ternary Pattern (LTP), (v) Local Configuration Pattern (LCP), and (vi) Rotated LBP (RLBP). Besides the texture descriptors from the LBP family, the authors implemented three other descriptors: (i) histogram feature, (ii) Haralick feature, and (iii) Gabor filter feature. The implementation of the the ten feature descriptors was done in MATLAB. The output of this process is a feature vector which is used as the input of the classification process. \\

Classification is the final process of the proposed framework (refer to Figure 1(c)). In order to classify OA/non-OA images, it is required to use machine learning algorithms to process the feature vector generated in the texture extraction process. Eight machine learning algorithms were applied: (i) Decision Tree (C4.5), (ii) Average One-Dependence Estimators (AODE), (iii) Bayesian Network (BN), (iv) Na\"ive Bayes Classifier, (v) Support Vector Machine (SVM), (vi) Logistic Regression, (vii) Sequential Minimal Optimization (SMO), and (viii) Backpropagation. The implementation of the machine learning algorithms on the feature vector was then evaluated using a number of typically used evaluation measures.

\section{Texture Descriptor}

Texture descriptor is one of the most important techniques to classify the similarity of images. The ten texture feature descriptors used in this research are: (i) histogram feature, (ii) Local Binary Pattern (LBP), (iii) Completed LBP (CLBP), (iv) Rotated LBP (RLBP), (v) LBP Rotation Invariant (LBP\textsubscript{ri}), (vi) LBP Histogram Fourier (LBP-HF), (vii) Local Ternary Pattern (LTP), (viii) Local Configuration Pattern (LCP), (ix) Haralick feature, and (x) Gabor filter feature. The texture descriptors used are described in the following subsections.
\subsection{The histogram features }
The histogram feature of the grey level image is received by state of the art histogram based feature, include: 
\begin{itemize}
	\item Mean
	\begin{equation}
	\mu= \sum_{i=1}^N (iP(i))
	\end{equation}
	Where  	P(i) is the probability distribution of bin i, which P(i) can be written as: 
	\begin{equation}
	P(i) =\dfrac{H(i)}{M}
	\end{equation}
	\hspace{1cm}H(i) is the histogram function and M is the number of blocks.
	
	
	\item Variance
	\begin{equation}
	\sigma^2= \sum_{i=1}^N (i - \mu)^2P(i)
	\end{equation}
	
	
	\item Skewness \\
	To define the Skewness equation, the standard deviation have to be found first: 
	\begin{equation}
	\sigma = \sqrt{ \sum_{i=1}^N (i - \mu)^2 P(i)}
	\end{equation}
	With the respect to equation (4), the skewness can be defined as: 
	\begin{equation}
	skew = \dfrac{1}{\sigma^3} \sum_{i=1}^N (i - \mu)^3 P(i)
	\end{equation}
	
	\item Kurtosis 
	\begin{equation}
	Kurtosis = \dfrac{1}{\sigma^4} \sum_{i=1}^N (i - \mu)^4 P(i)
	\end{equation}
	
	\item Energy 
	\begin{equation}
	Energy= \sum_{i=1}^N [P(i)]^2
	\end{equation}
	
	
	\item Entropy 
	\begin{equation}
	Entropy= - \sum_{i=1}^N P(i) log_2 [P(i)]
	\end{equation}
\end{itemize}

\subsection{Local Binary Pattern (LBP)} 
Local Binary Pattern (LBP) \cite{Ojala1996} is used to label the pixel which is applied thresholding the neighborhood of each pixel with the output as the binary number. The basic functionality of the LBP operator is shown in figure 3 below: 
\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\linewidth]{pic/fig2}
	\caption{LBP Operator.}
	\label{fig:fig2}
\end{figure}\\
In addition, LBP at pixel (x\textsubscript{c}, y\textsubscript{c}) can be calculated by the equation below: 
\begin{equation}
LBP_{P,R} (x_c,y_c) = \sum_{P=0}^{P-1} S(i_P - i_c)2^P
\end{equation}
Where \\ 
P is the pixels surround in the circle neighborhood. \\
R is a radius of circle. \\
Ic  and ip are the grave-level values of the center point. \\
s(x) is a function which is represented as: \\
\begin{equation}
s(x) = \left\{ \begin{array}{rcl}
1 & \mbox{if}
& x\geq0 \\ 0 & \mbox{if} & x <0 \\

\end{array}\right.
\end{equation}
Besides LBP, there is another LBP texture descriptor called Completed LBP (CLBP) that uses the basic functionality of LBP.

\subsection{ Completed LBP (CLBP)} 

In CLBP \cite{Guo2010} a local region is defined by a center pixel and a local difference sign-magnitude transform (LDSMT). In the research study is focused on LDSMT, which breaks down the image local structure into two components: (i) the difference signs (CLBP\_S), and (ii) the difference magnitudes (CLBP\_M). The implementation of CLBP\_S and CLBP\_M are shown in Figure 3:\\
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.45\linewidth]{pic/fig3}
	\caption{Example of CLBP Operations}
	\label{fig:fig3}
\end{figure}
\subsection{Rotated LBP (RLBP)}
Rotated LBP (RLBP) \cite{Mehta2013}, sometimes calls Dominant Rotated LBP (DRLBP) \cite{Mehta2016} is rotation technique on LBP around the center pixel. When the reference in the circular neighborhood token by dominant direction, then the weights are assigned with respect to dominant direction. The figure 4 is shown the rotation of LBP: \\ \\  
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.99\linewidth]{pic/fig4}
	\caption{Implementation of RLBP.}
	\label{fig:fig4}
\end{figure} \\
The RBLP defined by the Equation:\\
\begin{equation}
RLBP_{P,R} = \sum_{p=0}^{P-1} S(g_p - g_c)2^{mod(p-D,P)}
\end{equation}
\subsection{LBP Rotation Invariant (LBP\textsubscript{ri})} 
LBP\textsubscript{ri} is the rotation invariant feature which is based on LBP. The LBP operator produces 2p different output values, corresponding to the 2P different binary patterns that can be formed by the P pixels in the neighbor set. In the research study have applied LBP\textsubscript{ri} each pixel with 8 neighbors, LBP\textsubscript{ri} with 8 bin can be defined by the equation as :  
\begin{equation}
LBP(x,y) = \sum_{P=0}^{7} S(i_P - i_x,y)2^P
\end{equation}

\subsection{LBP Histogram Fourier (LBP-HF)}
LBP-HF is a rotation-invariant image descriptor based on uniform LBPs. The LBP-HF descriptor is formed by first computing a non-invariant LBP histogram over the whole region and then constructing rotationally invariant features from the histogram. LBP-HF is generally used for static features which used Fast Fourier Transform to calculate global features from uniform LBP histogram instated of calculating invariant at each pixel independently. This makes LBP\textsubscript{ri} feature set a subset of LBP-HF, LBP\textsubscript{ri} is discussed in the next sub-section. Figure 5 is shown the LBP-HF features work: \\ \\ \\
\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\linewidth]{pic/fig5}
	\caption{The implementation of LBP-HF feature for rotation invariant image description.}
	\label{fig:fig5}
\end{figure} \\
With the respect to figure 5, 
\texttt{\noindent
	\newline\noindent
	If α=\ang{45}, local binary pattern\\
	\phantom{x}\hspace{10ex}00000010 $\Rightarrow$  00000100 \\
	\phantom{x}\hspace{10ex}00000100 $\Rightarrow$  00001000,...,\\
	\phantom{x}\hspace{10ex}11111000 $\Rightarrow$  11110001,...,\\
	Similarity if α = K * \ang{45}, as a consequence, the pattern have to be circularly rotated with k steps. \\
}
\subsection{Local Configuration Pattern (LCP)}
Local Configuration Pattern (LCP) is a rotation invariant image description technique. LCP decompose the information architecture of an image into two states include: (i) local structural information and (ii) microscopic configuration (MiC) information that consists of image configuration and pixel-wise interaction relationships \cite{Guo2011}. For local structure, information is directly related to the basic of LBP, while the MiC Used to develop for exploring microscopic configuration information. 
The local structure concept implementation is shown in the figure 6 :
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.69\linewidth]{pic/fig6}
	\caption{The concept of LCP.}
	\label{fig:fig6}
\end{figure} \\
From Figure 6 it can be seen that Figure 6(a) and Figure 6(b) are considered to be the same pattern type by LBP, but with the implementation of LBP with local invariant information; pattern Figure 6(a) and Figure 6(b) are distinguished, while Figure 6(b) and Figure 6(c) are considered as the same pattern type due to the same value of variance. In contrast, Figure 6(b) and Figure 6(c) are different in MiC, which MiC based on textural properties. \\

For microscopic configuration information is defined as the modeling of microscopic configuration which expresses with the Equation 29: 
\begin{equation}
E(a_0,....,a_{P-1}) = |g_c - \sum_{i=0}^{P-1} a_ig_i|
\end{equation}
Where \\
g\textsubscript{c} and g\textsubscript{i} are intensity center pixel values and neighboring pixels.\\
a\textsubscript{i}(i=0,...,P-1) are weighting parameters associated with g\textsubscript{i} \\
E(a\textsubscript{0},...,a\textsubscript{P-1}) is the reconstruction error regarding model parameters of a\textsubscript{i}
\subsection{Local Ternary Pattern (LTP)}
With the basic idea of LBP which is analyzed on the central pixel i\textsubscript{c} which tend to be sensitive to noise particularly in near-uniform image regions, and to smooth weak illumination gradients, then the idea of LTP is come up to be improved in this issue.  LTP can be calculated be gray-level in a zone of width $\pm$ t. The s(x) of LBP is replaced by 3-valued function s\textsubscript{t}(u,i\textsubscript{c},t). 
\begin{equation}
s\textsubscript{t}(u,i_c,t) = \left\{ \begin{array}{rcl}
1 & 
& u\geq i_c+t \\ 0 &  & |u - i_c| <t \\
-1 & & u \leq i_c -t

\end{array}\right.
\end{equation}

 \subsection{Haralick}
Haralick features are determined by using kharalick() function and the basic of Haralick features is the gray-level co-occurrence matrix (GLCM). Haralick features have divided into 14 features which are calculated from the statistic of basic GLCM including: 


\begin{itemize}
	\item Angular Second Moment (ASM)
	\begin{equation}
	ASM = \sum_{i=1}^N\sum_{j=1}^N (P(i,j)^2)
	\end{equation}	
	
	\item Contrast
	\begin{equation}
	Contrast = \sum_{n=0}^{N -1}n^2{\sum_{i=1}^{N}\sum_{j=1}^{N} P(i,j)}, |i - j| =n
	\end{equation}
	
	
	\item Correlation \\ 
	\begin{equation}
	Correlation = \dfrac{\sum_{i=1}^N\sum_{j=1}^N (ij)P(i,j)-\mu_x \mu_y}{\sigma_x \sigma_y} 
	\end{equation}
	
	\item Variance  
	\begin{equation}
	\sigma^2= \sum_{i=1}^N\sum_{j=1}^N (i - \mu)^2P(i,j)
	\end{equation}
	
	\item Inverse Difference Moment(IDM) 
	\begin{equation}
	IDM=\sum_{i=1}^N\sum_{j=1}^N \dfrac{1}{1+(i-j)^2} P(i,j)
	\end{equation}
	
	
	\item Sum Average 
	\begin{equation}
	Sum Average= \sum_{i=2}^{2N} iP_{x+y}(i) 
	\end{equation}
	
	\item Sum Variance 
	\begin{equation}
	Sum Variance = \sum_{i=2}^{2N} (i-f_8)^2P_{x+y}(i) 
	\end{equation}
	
	\item Sum Entropy 
	\begin{equation}
	Sum Entropy= - \sum_{i=2}^{2N} P_{x+y}(i) log{P_{x+y}(i)}
	\end{equation}
	
	\item Entropy 
	\begin{equation}
	Entropy= - \sum_{i=1}^N\sum_{j=1}^N P(i,j) log[P(i,j)]
	\end{equation}
	
	\item Difference Variance 
	\begin{equation}
	Difference Variance = \sum_{i=0}^{N-1}i^2 P_{x-y}(i)
	\end{equation}

	\item Difference Entropy 
	\begin{equation}
	Difference Energy= - \sum_{i=0}^{N-1} P{x-y}(i) log [P_{x-y}(i)]
	\end{equation}
	
	\item Information Measure of Correlation 1(IMC1)
	\begin{equation}
	IMC1= \dfrac{HXY-HXY1}{max{HX,HY}}
	\end{equation}
	
	\item Information Measure of Correlation 2(IMC2)
	\begin{equation}
	IMC2=\sqrt{ 1-exp[-2(HXY2-HXY)]}
	\end{equation}
	Where 
	\begin{equation}
	\begin{split}
	HXY=- \sum_{i=1}^N \sum_{j=1}^N P(i,j) log(P(i,j)),\\
	HXY1= -\sum_{i=1}^N \sum_{j=1}^N P(i,j) log{P_x(i)P_y(i)},\\
	HXY2=-\sum_{i=1}^N \sum_{j=1}^N P_x(i)P_y(j) log{P_x(i)P_y(j)}
	\end{split}
	\end{equation}
	HX and HY are the entropies of P\textsubscript{x} and P\textsubscript{y}
	
	\item Maximum Correlation Coefficient(MCC) 
	\begin{equation}
	MCC= \sqrt{\sum_{k=1}^N \dfrac{P(i,k)P(j,k)}{P_x(i)P_y(j)}}
	\end{equation}
\end{itemize}





\subsection{Gabor filter }
Gabor filter is another texture extraction technique which is used to analyze texture for specific image’s local region with the specific frequency and specific direction. Gabor filter is in fact of the 2D Gabor filter bank that consists different parameters including frequencies, orientations and smooth parameters of Gaussian envelope. In addition, Gabor filter bank of pixel (x, y) can be founded by the Equation 13 below: 
\begin{equation}
G(x,y)\equiv e^{-{\dfrac{(x-x_0)^2}{2\sigma^2_x}-\dfrac{(y-y_0)^2}{2\sigma^2_y}}} e^{j(\omega_{x0}x+\omega_{y0}y)}
\end{equation}
where \\
$\omega$\textsubscript{x0}   and   $\omega$\textsubscript{y0} \hspace{0.2cm}   are the centre frequency of x and y direction.\\
$\sigma$\textsubscript{x}    and   $\sigma$\textsubscript{y}   \hspace{0.5cm}  are the standard deviation of the Gaussian function along x and y direction. 

%The author names and affiliations could be formatted in two ways:
%\begin{enumerate}[(1)]
%\item Group the authors per affiliation.
%\item Use footnotes to indicate the affiliations.
%\end{enumerate}
%See the front matter of this document for examples. You are recommended to conform your choice to the journal you are submitting to.

\section{Feature Selection}
Feature selection is one of the most important in the research work, this process selects the useful feature or reducing data dimensionality to the classification process. There are five different feature selection techniques are applied in the research work:(i) Correlation-based Feature Selection, (ii) Chi-square, (iii) Gain Ration, (iv) Information Gain, and (v) Relief. The detail of each technique is presented in the next subsection: 

\subsection{Correlation-based Feature Selection (CFS)}
Correlation Feature Selection (CFS) is widely used with the highly correlated to the class feature but CFS produce a low intercorrelation \cite{Hall1999}. In addition, in CFS have applied symmetric uncertainty which is the technique use reduce the redundancy of feature.  The symmetric uncertainty which applies to two nominal attributes A and B is given by the equation: 
\begin{equation}
U(A,B) =2 \dfrac{H(A)+H(B)-H(A,B)}{H(A) + H(B)}
\end{equation}
Where \\
H represents as the entropy function.\\
H(A, B) the joint entropy of A and B. \\
The value of symmetric uncertainty can start from 0 till 1. 
With the respect to equation (31), CFS can be defined as: 
\begin{equation}
	CFS= \dfrac{\sum_{j=i}^m U(A_j,C)}{\sqrt{\sum_{i=1}^m \sum_{j=1}^m U(A_i,A_j)}}
\end{equation}
Where \\
C refer to the class of feature. \\
(A\textsubscript{i}, A\textsubscript{j} ) indicates a pair of attributes in the set of features.


\subsection{Chi-square ($\chi^2$)}
In the research, the measure of the lacking independence between a feature and a class can be calculated by Chi-square ($\chi^2$) \cite{Plackett1983}. In the implementation of research work by Chi-square ($\chi^2$), the feature is ranked from the most useful to the less. Chi-square ($\chi^2$) can be given as the function below: 
\begin{equation}
\chi^2 = \sum_{i=1}^{c} \sum_{j=1}^{r} \dfrac{(O_{ij} - E_{ij})^2}{E_{ij}}
\end{equation}
Where\\
O\textsubscript{ij}  is the observed frequency.\\ 
E\textsubscript{ij} is ij is the expected frequency. 


\subsection{Information Gain}
Information gain (IG) measures the amount of information in bits about the
class prediction, if the only information available is the presence of a feature
and the corresponding class distribution\cite{Roobaert}.IG use to select the test attribute at each node. In other words, IG is a feature evaluation method which base on entropy \cite{Lei2012}. IG can be calculated by of a term in classification of information that can be used.  IG can be defined as the Equation 34 below: 
 
\begin{equation}
G(D,t)=-\sum_{i=1}^nP(C_i)logP(C_i) + P(t)\sum_{i=1}^nP(C_i|t)logP(C_i|t)+P(\bar{t})\sum_{i=1}^nP(C_i|\bar{t})logP(C_i|\bar{t})
\end{equation}
Where\\
 C is a set of document collection, feature t. The value of information gain G(D,t) is greater mean t is more useful for the classification for C. This t should be selected.
 
\subsection{Gain Ratio}
 Gain ration (GR) is the updating or correction of information gain (IG). Information gain is used in the decision tree to select the test attribute ate each decision tree node \cite{Han2012}. Hence, the implementation of RG in order to reduce the IG’s bias, while choosing an attribute of taking number and size of branches.  GR of attribuate(attr) can be written as equation below: 
 \begin{equation}
 GR(attr)=\dfrac{Gain(attr)}{Entropy(attr)}
 \end{equation}
 
 \subsection{ReiefF}
 The final feature selection technique in the research refers to relief, relief is a weight based algorithm where the result in the relevant of feature and classification for weight based \cite{Kira1994}. In addition, relief will remove the features if the weight is less than the clearly limit. The relief algorithm chooses a sample M in training data S, then the nearest neighbor of the sample H of the sample which has the same group with M, called Near Hit. On the other hand, the reverse categories of M can be found by nearest neighbor sample M from the sample, called Miss. 

 
 \section{Classification}
 Classification is a process which is used to classify the OA grade, in the processes have applied nine difference machine learning algorithm include: 

 \subsection{Decision Tree(C 4.5)}
 	Decision tree is a well-known algorithm for machine learning and classification technique \cite{Quinlan1986}.  The decision tree has been considered as a direct tree that consists of root node, internal node, and leaf node. For root node is the main root or parent node and has no incoming edges, while leaf root is the root is at the bottom of the tree and has no outgoing edges. For internal node refer to test on an attribute, while branch defines as the output of that test. 
 
 \subsection{Average One-Dependence Estimators (AODE)}
 	Average one-dependence estimators (AODE) is an improvement of the naïve Bayesian classifier and is a probability classification learning technique \cite{Webb2005}. AODE comes from the naïve Bayes classifier attributed-independence problem. The implement of AODE is to address the attribute-independence problem in naïve Bayes. For instance, in the class y which has a set of feature x\textsubscript{1},..., x\textsubscript{n}, then AODE can be applied to find the probability of each class y by the Equation 36 as follows: 
 	\begin{equation}
 	\hat{P}(y|x_1,...,x_n) = \dfrac{\sum_{i:1\leq i\leq n \wedge F(x_i) \geq m} \hat{P}(y,x_i)\prod_{j=1}^n \hat{P}(x_i|y,x_i)}{ \sum_{y'\in Y}  \sum_{i:1\leq i\leq n \wedge F(x_i) \geq m} \hat{P}(y',x_i) \prod_{i=1}^n \hat{P}(x_j|y',x_i) }
 	\end{equation}
 	Where \\
 	$\hat{P}$ is an estimate of P \\
 	F  is the frequency \\
 	m is a user specified minimum frequency.
 	
 	
 \subsection{Bayesian Network (BN)}
 	Bayesian network (BN) or probabilistic networks (PNs) is a graphical probability model used for reasoning and the decision making in uncertainty \cite{Friedman1998}. In other words, the Bayesian network is a directed acyclic graph (DAG) and each node n $\in$ N of BN represents a domain variable or dataset attribute. In addition, the Bayesian network highly depends on Bayes’ rule. The Bayes' rule can be written as follows: 
 	Assume A\textsubscript{i}  attribute where i= 1,...,n, and take value a\textsubscript{i}  where i= 1,...,n
 	
 	Assume C as class label attribute and U=(a\textsubscript{1},..., a\textsubscript{n}) as unclassified test instance. U will be classified into class  C based on Bayes’ rule is represented as:
 	\begin{equation}
 	P(C|U)=arg\ max P(C)P(U|C)
 	\end{equation}
 	
 \subsection{Na\"ive Bayes Classifier}
 	Na\"ive Bayes is one of the well-known of Bayesian techniques which called state-of-the-art of the Bayesian. In  other words, Na\"ive bayes classifier is a technique that use a simple probabilistic classifier based on the implementation of Bayes' theorem combined with strong (naive) independence assumptions \cite{Lowd2005}. In the work of Na\"ive Bayes classifier have assumed all the attribute in the same class has been considered as independent given class label. With the respect to Bayes’ rule, the Na\"ive Bayesian has been modified as the equation below:
 	\begin{equation}
 	P(C|U) = arg\ max P(C) \prod_{i=1}^n P(A_i|C)
 	\end{equation}
 	
\subsection{Support Vector Machine(SVM)}
 	Support vector machine (SVM) is a popular liner classifier and widely used for the classification task. SVM is performed for the best separating by constructing an N-dimensional hyperplane between two training sample classes in the feature set \cite{Cortes1995}. In SVM classifier have divided into two categories: \\

 		\subsubsection{Linear classification}
 		In the liner classification, the SVM can be divided into two type of classification: i) linear separable case and ii) linear non-separable case. 
 		In linear separable case, SVM with the training data {x\textsubscript{i} , y\textsubscript{i}}, y\textsubscript{i}  $\in${-1,+1} , i = 1,...,n ,  can be defined as the equation as follows: 
 		\begin{equation}
 		\left\{ \begin{array}{rcl}
 		x_i . w + b \geq +1 & \mbox{for} 
 		y_i = +1 \\ x_i . w + b \leq -1 & \mbox{for}	y_i = -1
 		
 		\end{array}\right.
 		\end{equation}
 		For the linear non-separable case, SVM equation is changed to: 
 		\begin{equation}
 		\left\{ \begin{array}{rcl}
 		x_i . w + b \geq +1 - \xi_i & \mbox{for} 
 		y_i = +1 \\ x_i . w + b \leq -1 +\xi_i & \mbox{for}	y_i = -1 \\ \xi_i \geq 0, i=1,n
 		
 		\end{array}\right.
 		\end{equation}
 		
 		\subsubsection{Nolinear classification}
 		In nolinear classification, svm equation can be written as: 
 		\begin{equation}
 		f(x) = \sum_{i=1}^{n_s} \alpha_i y_i P(x_i,x) +b
 		\end{equation}
 		Where \\
 		n\textsubscript{s} is the number of support vector. \\
 		α  is non-negative Lagrange multipliers\\
 		P (x, y) is Polynominal of degree m: k(x,y)=(x.y+1)\textsuperscript{m}
 \subsection{Logistic Regression}
 	Logistic regression is a well-known statistic regression model and offshoot the ordinary regression \cite{Wilson2015}. in the research, the logistic regression has been applied to the dependent variable. In addition, in logistic regression used logistic function, also recognized as the sigmoid function which use to compute logistic model. The logistic model has defined with the equation: 
 	\begin{equation}
 	logit(p_t) =x_tb+e_t; p_t=P(y_t =1|x_t,b)
 	\end{equation}
 	Where \\
 	yt ∈ {0,1} 
 	x\textsubscript{t} is the regression vector, x\textsubscript{t} = [1, x\textsubscript{1},x\textsubscript{2},..., x\textsubscript{n}]\\
 	b is the model parameters vector, b = [b\textsubscript{0}, b\textsubscript{1},..., b\textsubscript{n}]’
 	P( | )  is the conditional probability function (pf) and 
 	logit() is the logistic function. The logit() can be represented as: 
 	\begin{equation}
 	logit(p)=ln(\dfrac{p}{1-p})
 	\end{equation}
 \subsection{Sequential Minimal Optimization}
 	Sequential Minimal Optimization (SMO) is the improvement from SVM to solve the quadratic programming (QP) optimization problem, the problem has happened during the SVM training \cite{Platt1998}. Furthermore, QP problem can be represented while SVM finds $\alpha_i$ , as the equation below: 
 	\begin{equation}
 	min \ L_D(\alpha)= \sum_{i=1}^n \alpha_i -\dfrac{1}{2}\sum_{i=1}^n \sum_{j=1}^n \alpha_i \alpha_j y_iy_j(x_ix_j)
 	\end{equation}
 	
 	\begin{equation}
 	s.t \ 0 \leq \alpha_i \leq C \quad  and \quad \sum_i^n \alpha_i y_i =0, \quad \forall i
 	\end{equation}
 	With the respect to the two equation above (44) and (45), SMO select the Smallest Optimization Problem (SOP) and solve the SOP. 
\subsection{The Back Propagation Algorithm}
 	The backpropagation algorithm is a famous in the neural network, the implementation of backpropagation algorithm is to calculate a gradient which is demanded in the calculation of the weights to be used in the network \cite{Kelley1960}. In other words, backpropagation is doing the task of learning the same to the neural network which is finding the minimum of the error function.



\section{Data Collection } 
\subsection{Dataset}
The dataset of the research is the research image which is collected from 2 local hospitals in Thailand. The number of images in the research use 131 images which divided into non-OA 63 images and OA has 68 images. Due to the privacy of each patient for each image, the researcher request only the image data without including any detail information for example age, sex, address, and etc.
\subsection{Region of Interest}
The dataset is collected with the known result of OA and non-OA case, which the OA case has 68 images in 131 images of all dataset. Furthermore, four different places are chosen to be ROI for texture analysis, the four ROIs are shown in the Figure 7 below: \\
\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\linewidth]{pic/fig9}
	\caption{The Four ROI of Texture Analysis}
	\label{fig:fig9}
\end{figure} \\
With the reference to the Figure 7,  there are four different ROIs, hence, the dataset of the research is divided into four different datasets which have 131 ROI images include (i)Medial Femur ROI dataset, (ii) Literal Femur ROI dataset, (iii) Medial Tibia dataset, and (iv) Literal Tibia dataset. \\ 
The four ROI datasets which are used to analyze and evaluate with image processing techniques and classification techniques present in section 8.Evaluation. 

\section{Evaluation}
The evaluation of the proposed approach to OA screening is presented in this section. 7272 experiments were conducted with respect to the proposed approach ( Only the most significant results obtained are presented). The evaluation was conducted by considering a case study directed at 131 digital x-ray image take in Posteo Anterior (PA) position. The data set comprised: (i) X control and (ii) Y OA images. Ten-fold Cross-Validation (TCV) was applied throughout and performance records in term of: (i) Area Under the ROC Curve (AUC), (ii) Accuracy (AC), (iii) Sensitivity (SN), (iv) Specificity (SP), (v) Precision (PR), and (vi) F-Measure (FM). The overall aim of the evaluation was to provide evidence that the OA condition can be easily detected using the proposed framework. To this end four sets of experiment were conducted with the following objectives:
\singlespacing1. Selection the best ROI from the best experiment result. 
\singlespacing2. Comparision the best feature descriptor for the research experiment. 
\singlespacing3. Studying the best feature selection technique for experiment.
\singlespacing4. Selection learning algorithm for the best classification result. \\ \\
For each objective is presented detail in sub-section 8.1-8.4: 

\subsection{The best ROI result}
The four ROIs: (i) Literal Femur(LF), (ii) Medial Femur(MF), (iii) Literal Tibia(LT), and (iv) Medial Tibia(MT) are selected to use for texture analysis for research experiment.Hence, there are four different dataset that each one contain of 131 sub-images.The result of each ROI is shown in Table 1.\\

%\begin {tabular}{|l|>{$}c<{$}|>{$}c<{$}|}\hline
%\backslashbox{ROI}{Algorithm} &AUC&AC&SN&SP&PR&FM\\\hline
%Literal Femur(LF) & 0 & 1\\\hline
%Medial Femur(MF) & 1 & 0\\\hline
%\end{tabular}
\begin{table}[h]
	\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
	\hline 
\backslashbox{ROI}{Algorithm} &AUC&AC&SN&SP&PR&FM\\
	\hline 
\cellcolor{blue!25}Lateral Femur(LF)	&\cellcolor{blue!25} 0.912 &\cellcolor{blue!25} 0.832  & \cellcolor{blue!25}0.832 &\cellcolor{blue!25}0.832  &\cellcolor{blue!25}0.832  & \cellcolor{blue!25}0.832 \\ 
	\hline 
Medial Femur(MF)	& 0.884 & 0.794 & 0.794 &0.792  &0.794  &0.794  \\ 
	\hline 
Lateral Tibia(LT)	&0.883  &0.809  & 0.809 &0.809  &0.809  &0.809  \\ 
	\hline 
Medial Tibia(MT)	&0.895  &0.802  &0.802  &0.802  &0.802  &0.802  \\ 
	\hline 
\end{tabular} 
\caption{The ROI best result comparison. }
\end{table}
From Table 1, the best result of ROIs is founded by LF which is applied by LBP feature descriptor with Bayes Network which is shown in the highlight color. The best result is recorded AUC value of 0.912. 


\subsection{The best feature descriptor  result}
The studying of feature descriptor and selection only the best result of each technigue is presented in this subsection. 10 texture descriptors are implemented in the research experiment include, (i) Histogram features, (ii) Local Binary Pattern (LBP), (iii) Completed LBP (CLBP), (iv) Rotated LBP (RLBP), (v) LBP Histogram Fourier (LBP-HF), (vi) LBP Rotation Invariant (LBP\_ri), (vii) Gabor, (viii) Haralick, (ix) Local Configuration Pattern (LCP) and (x) Local Ternary Pattern (LTP). The best result of each feature descriptor are shown in Table.2 below: \\

\begin{table}[h!]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|}
		\hline 
		\backslashbox{Texture \\ Descriptor}{Algorithm} &AUC&AC&SN&SP&PR&FM\\
		\hline 
		Histogram	& 0.757 & 0.695  & 0.695 &0.69  &0.695  & 0.693 \\ 
		\hline 
		CLBP		& 0.882 & 0.763 & 0.763 &0.762  &0.763  &0.763  \\ 
		\hline 
		Gabor		&0.883  &0.786  &0.786  &0.786  &0.786  &0.786  \\ 
		\hline 
		Haralick 	&0.695  &0.664  &0.664  &0.67  &0.672  &0.662  \\ 
		\hline 
	\cellcolor{blue!25}	LBP 		&\cellcolor{blue!25}0.912  &\cellcolor{blue!25}0.832  &\cellcolor{blue!25}0.832  &\cellcolor{blue!25}0.832  &\cellcolor{blue!25}0.832  &\cellcolor{blue!25}0.832  \\ 
		\hline
		LBP-hf 		&0.773  &0.71  &0.71  &0.717  &0.71  &0.709  \\ 
		\hline
	    LBP\_ri 	&0.812  &0.771  &0.771  &0.771  &0.771  &0.771  \\ 
		\hline
		LCP		 	&0.783  &0.725  &0.725  &0.724  &0.725  &0.725  \\ 
		\hline
		LTP		 	&0.816  &0.756  &0.756  &0.761  &0.763  &0.755  \\ 
		\hline
		RLBP	 	&0.895  &0.809  &0.809  &0.81  &0.81  &0.809  \\ 
		\hline
	\end{tabular} 
	\caption{The ROI best result comparison. }
\end{table}
With the respect to Table 2, LBP can make the best result with value AUC of 0.912 which is shown in the highlight color. As a result, the most appropriate of the result was obtained by applying the LBP descriptor.  

\subsection{The Best feature selection}
A set of experiments to compare the operation of various suggested feature selection algorithm: (i) Correlation-based Feature Selection, (ii) Chi-square, (iii) Gain Ration, (iv) Information Gain, and (v) Relief. the beast result of each algorithm is illustated in  Table 3:  

\begin{table}[h!]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|}
		\hline 
		\backslashbox{Texture \\ Selector}{Algorithm} &AUC&AC&SN&SP&PR&FM\\
		\hline 
	\cellcolor{blue!25}CFS			& \cellcolor{blue!25} 0.912 & \cellcolor{blue!25}0.832  & \cellcolor{blue!25}0.832 & \cellcolor{blue!25}0.832  & \cellcolor{blue!25}0.832  & \cellcolor{blue!25}0.832 \\ 
		\hline 
		Chi-Square	& 0.699 & 0.687 & 0.687 &0.687  &0.687  &0.687  \\ 
		\hline 
		Gain Ratio		&0.709  &0.687  &0.687  &0.687  &0.687  &0.687  \\ 
		\hline 
		Information Gain 	&0.699  &0.687  &0.687  &0.684  &0.687  &0.687 \\ 
		\hline 
		Relief 		&0.699  &0.679  &0.679  &0.674 &0.681  &0.677  \\ 
		\hline
	\end{tabular} 
	\caption{The best feature selection result comparison. }
\end{table}
With reference to table 3, the best result of CFS in the hightlight color can be founded out by LF applied with LBP and Bayes Network, while Chi-square result is presented by LF applied with GLCM and Naïve Bay for AUC value and others value from MT applied with CLBP and decision tree. For the gain ratio, the best result, have founded by LT applied with LBP\_ri and decision tree binary true, and others value are pointed out by LT applied with LTP and SMO. In the information gain, the best result is presented by LF applied with GLCM and Naïve Bay, while others value by LT applied with LTP and SMO. Lastly, the best result of Relief is received from LF applied with GLCM and Naïve Bay. The best result of the learning algorithm is presented in next subsection.


\subsection{The Best learning algorithm }
Learning of each leaning algorithm for experiment is disccused in this subsection. The best result of each learning algorithm is selected to presented in Table 4: 
\begin{table}[h!]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|}
		\hline 
		\backslashbox{Machine Learning \\ Algorithm}{Algorithm} &AUC&AC&SN&SP&PR&FM\\
		\hline  
		C4.5		&0.757&	0.779&	0.779&	0.78&	0.78&	0.779\\
		\hline
		C4.5 binary tree(true)	&0.766	&0.74	&0.74	&0.736	&0.742	&0.739 \\
		\hline 
		AODE	&0.896	&0.809	&0.809	&0.804	&0.809	&0.809 \\
		\hline 
	\cellcolor{blue!25}	Bayes network	& \cellcolor{blue!25}0.912	& \cellcolor{blue!25}0.832	& \cellcolor{blue!25}0.832	& \cellcolor{blue!25}0.832	& \cellcolor{blue!25}0.832	& \cellcolor{blue!25}0.832\\
		\hline 
		Naïve bay	&0.903	&0.817	&0.817	&0.816	&0.817	&0.817 \\
		\hline 
		SVM			&0.715	&0.718	&0.718	&0.711	&0.72	&0.715 \\
		\hline 
		Logistic	&0.904	&0.84	&0.84	&0.844	&0.847	&0.839 \\
		\hline 
		SMO			&0.771	&0.771	&0.771	&0.771	&0.771	&0.771 \\
		\hline 
		Multilayer	&0.851	&0.771	&0.771	&0.77	&0.771	&0.771 \\
		\hline 
	\end{tabular} 
	\caption{The best learning algorithm result comparison. }
\end{table}

From Table 4, the best result of decision tree have gained by the implementation of MT applied with CLBP and CFS, while decision tree with the binary true best result is pointed out by LT applied with LBP and CFS for AUC value and others from LTP applied with LTP and CFS. For the AODE result is presented by LF applied with LBP and CFS for AUC value, LT applied with LBP and CFS for SP value, and others are founded by LT or LF applied with LBP and CFS. The implementation of LF applied with LBP and CFS have produced the best result of Bayes Network, while the best result of Naïve bay is produced by LF applied with LBP and CFS for AUC value and others values by LT applied with LBP and CFS. Furthermore, the best result of SVM can be founded out by the implementation of LF applied with LBP\_ri and CFS, while the logistic result is presented by the implementation of LF applied with LBP and CFS. For the SMO best result is a reference to the implementation of LF applied with RLBP and CFS. Lastly, the multilayer finds out by LF applied with RLBP and CFS for AUC, LT and others are applied from LF applied with LBP\_ri with CFS.

\section{Conclusion}
Early diagnosis of OA and non-OA applied with four sub-image, various types of feature extractor and 9 generator classifier were presented. As a result, the four major propose are shown: i) the best result of ROI went to Literal Femur (LF), ii) LBP become the best descriptor in the research study, iii) The Best feature selection in the research is CFS, and iv) The Best learning algorithm  is represented by Bayes network. 
\section{Acknowledgement}
We would like to our gratitude to the Bangkok hospital Phuket branch and Dibuk hospital for providing x-ray dataset in this research study. We would like to give a special thanks to MD. Sirisak Yaisoongnern for managing to the process of data collection and million thanks to MD. Chaowakon Saehang for sharing his valuable knowledge in OA grading field. 

\section*{References}

\bibliography{normalOA}

\end{document}